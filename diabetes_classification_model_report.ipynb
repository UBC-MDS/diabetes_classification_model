{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting if an individual is diabetic from health factor\n",
    "\n",
    "by Angela Chen, Ella Hein, Scout McKee, Sharon Voon 2023/12/01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from myst_nb import glue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/plain": "'0.852 (+/- 0.001)'"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "dt_test_score"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/papermill.record/text/plain": "'0.847 (+/- 0.000)'"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "lr_test_score"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/papermill.record/text/plain": "'0.847 (+/- 0.000)'"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "optimized_knn_test_score"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/papermill.record/text/plain": "'0.847 (+/- 0.000)'"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "dummy_score"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/papermill.record/text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fit_time</th>\n      <th>score_time</th>\n      <th>test_score</th>\n      <th>train_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Dummy</th>\n      <td>0.018 (+/- 0.001)</td>\n      <td>0.002 (+/- 0.000)</td>\n      <td>0.847 (+/- 0.000)</td>\n      <td>0.847 (+/- 0.000)</td>\n    </tr>\n    <tr>\n      <th>Decision tree</th>\n      <td>0.217 (+/- 0.002)</td>\n      <td>0.005 (+/- 0.000)</td>\n      <td>0.852 (+/- 0.001)</td>\n      <td>0.852 (+/- 0.000)</td>\n    </tr>\n    <tr>\n      <th>Logistic regression</th>\n      <td>0.073 (+/- 0.002)</td>\n      <td>0.004 (+/- 0.000)</td>\n      <td>0.847 (+/- 0.000)</td>\n      <td>0.847 (+/- 0.000)</td>\n    </tr>\n    <tr>\n      <th>Knn</th>\n      <td>0.027 (+/- 0.005)</td>\n      <td>1.555 (+/- 0.099)</td>\n      <td>0.847 (+/- 0.000)</td>\n      <td>0.847 (+/- 0.000)</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "application/papermill.record/text/plain": "                              fit_time         score_time         test_score  \\\nDummy                0.018 (+/- 0.001)  0.002 (+/- 0.000)  0.847 (+/- 0.000)   \nDecision tree        0.217 (+/- 0.002)  0.005 (+/- 0.000)  0.852 (+/- 0.001)   \nLogistic regression  0.073 (+/- 0.002)  0.004 (+/- 0.000)  0.847 (+/- 0.000)   \nKnn                  0.027 (+/- 0.005)  1.555 (+/- 0.099)  0.847 (+/- 0.000)   \n\n                           train_score  \nDummy                0.847 (+/- 0.000)  \nDecision tree        0.852 (+/- 0.000)  \nLogistic regression  0.847 (+/- 0.000)  \nKnn                  0.847 (+/- 0.000)  "
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "model_score_table"
      }
     },
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "glue() got an unexpected keyword argument 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\git\\DSCI522\\DSCI_522_Group2\\report\\diabetes_classification_model_report.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/git/DSCI522/DSCI_522_Group2/report/diabetes_classification_model_report.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m coef_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39m../results/tables/feature_importances.csv\u001b[39m\u001b[39m\"\u001b[39m,index_col\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mround(\u001b[39m2\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/git/DSCI522/DSCI_522_Group2/report/diabetes_classification_model_report.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m coef_df \u001b[39m=\u001b[39m coef_df\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mcoefficients\u001b[39m\u001b[39m\"\u001b[39m],ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/git/DSCI522/DSCI_522_Group2/report/diabetes_classification_model_report.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m glue(\u001b[39m\"\u001b[39;49m\u001b[39mcoef_table\u001b[39;49m\u001b[39m\"\u001b[39;49m, coef_df, display\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/git/DSCI522/DSCI_522_Group2/report/diabetes_classification_model_report.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m glue(\u001b[39m\"\u001b[39m\u001b[39mhighest_importance_coeff\u001b[39m\u001b[39m\"\u001b[39m, coef_df[\u001b[39m'\u001b[39m\u001b[39mcoefficients\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m],display\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/git/DSCI522/DSCI_522_Group2/report/diabetes_classification_model_report.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m confusion_matrix_dt \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39m../results/tables/confusion_matrix_DT.csv\u001b[39m\u001b[39m\"\u001b[39m,index_col\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: glue() got an unexpected keyword argument 'index'"
     ]
    }
   ],
   "source": [
    "# Define variables with glue here\n",
    "scores_df = pd.read_csv(\"../results/tables/model_comparison_results.csv\",index_col=0)\n",
    "glue(\"dt_test_score\", scores_df['test_score'].values[1], display = False) \n",
    "glue(\"lr_test_score\", scores_df['test_score'].values[2], display = False) \n",
    "glue(\"optimized_knn_test_score\", scores_df['test_score'].values[3],display=False)\n",
    "glue(\"dummy_score\", scores_df['test_score'].values[0], display = False) \n",
    "glue(\"model_score_table\", scores_df, display=False)\n",
    "\n",
    "coef_df = pd.read_csv(\"../results/tables/feature_importances.csv\",index_col=0).round(2)\n",
    "coef_df = coef_df.sort_values(by=[\"coefficients\"],ascending=False)\n",
    "glue(\"coef_table\", coef_df, display=False)\n",
    "glue(\"highest_importance_coeff\", coef_df['coefficients'].values[0],display=False)\n",
    "\n",
    "confusion_matrix_dt = pd.read_csv(\"../results/tables/confusion_matrix_DT.csv\",index_col=0)\n",
    "glue(\"false_negative\", confusion_matrix_dt.iloc[1,0],display=False)\n",
    "glue(\"false_positive\", confusion_matrix_dt.iloc[0,1],display=False)\n",
    "\n",
    "best_params = pd.read_csv(\"../results/tables/best_hyperparams.csv\",index_col=0)\n",
    "glue(\"knn_bestparam\", best_params.loc[:, \"n_neighbours\"][0],display=False)\n",
    "glue(\"tree_bestparam\", best_params.loc[:, \"max_depth\"][0],display=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "This project endeavors to develop a predictive classification model for ascertaining an individual's diabetic status, while comparing the efficiency of optimized decision tree and optimized k-nearest neighbours (k-nn) algorithms. The dataset used in this analysis is collected through the Behavioral Risk Factor Surveillance System (BFRSS) by the Centers for Disease Control and Prevention (CDC) for the year 2015. Notably, the primary determinant influencing the prediction is identified as the feature General Health (GenHlth), displaying a coefficient of {glue:text}`highest_importance_coeff`  as revealed by the logistic regression model. The optimized decision tree model demonstrates a test score of {glue:text}`dt_test_score`,while the optimized k-nn model yields a test score of {glue:text}`optimized_knn_test_score`. Both of the test scores are relatively close to the validation score which shows that the model will generalized well to unseen data, however, there is still room for improvement in the test score. \n",
    "\n",
    "Our final classsifer is chosen to be the Desicion Tree model as it has both the highest test and train score in comparison with the optimized k-nn model. However, from the confusion matrix, we can see that our model has made {glue:text}`false_negative` type II error, which predicted the individual as non-diabetic when they are actually diabetic. On the other hand, it has also made {glue:text}`false_positive` type I error, which predicted the individual as diabetic when they are actually non-diabetic. In our case, both type II error and type I error is equivalently important as injecting insulin in a non-diabetic individual can be fatal and vice versa. Hence, we chose f1 score as our scoring matrix which is a hormonic balance between both type I and type II errors. \n",
    "\n",
    "From this result, we can also see that there is a huge class imbalance in between diabetic and non-diabetic class, which will be taken into account in the preprocessor in the next version of this analysis.\n",
    "\n",
    "Continued efforts in these areas will contribute to the model's robustness and reliability, making it more suitable for deployment in a clinical setting.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Diabetes mellitus, commonly referred to as diabetes is a disease which impacts the bodyâ€™s control of blood glucose levels {cite}`sapra_bhandari_diabetes`. It is important to note that there are different types of diabetes, although we do not explore this discrepancy in this project {cite}`sapra_bhandari_diabetes`. Diabetes is a manageable disease thanks to the discovery of insulin in 1922. Globally, 1 in 11 adults have diabetes {cite}`sapra_bhandari_diabetes`. As such, understanding the factors which are strongly related to diabetes can be important for researchers studying how to better prevent or manage the disease. In this project, we create several machine learning models to predict diabetes in a patient and evaluate the success of these models. We also explore the coefficients of a logistic regression model to better understand the factors which are associated with diabetes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "### Data\n",
    "The dataset used in this project is a collection of the Centers for Disease Control and Prevention (CDC) diabetes health indicators collected as a response to the CDC's BRFSS2015 survey. The data were sourced from the UCI Machine Learning Repository {cite}`BurrowsEtAl` which can be found [here](https://archive.ics.uci.edu/dataset/891/cdc+diabetes+health+indicators). The file specifically used from this repository for this analysis includes 70, 692 survey responses from which 50% of the respondents recorded having either prediabetes or diabetes. Each row in the dataset represents a recorded survey response including whether or not the responded has diabetes or prediabetes, and a collection of 21 other diabetes health indicators identified by the CDC. \n",
    "\n",
    "### Analysis\n",
    "In our efforts to determine the best model for classifying a patient with diabetes or prediabetes as opposed to no diabetes or prediabetes, we performed hyperparamter optimization on both a knn model and a decision tree model. We also explored a logistic regression model to gain insight into which features may contribute most to a classification of diabetes. All features from the original dataset were included in each model. In all cases, the data were split into training and testing datasets, with 80% of the data designated as training and 20% as testing. The data was preprocessesed such that all continuous (non-binary) variables were scaled using a scikit-learn's StandardScaler function. Model performance was tested using a 10 - fold cross validation score. Feature importance was investigated using the coefficients generated by the logistic regression algorithm. The k-nn algorithm's hyperparameter K was optimized using the F1 score as the classification metric. Python programming (Van Rossum and Drake 2009) was used for all analysis. The following Python packages were used for this analysis: Pandas {cite}`mckinney-proc-scipy-2010`, altair {cite}`vanderplas2018altair`, and scikit-learn {cite}`pedregosa2011scikit`.\n",
    "\n",
    "### Results & Discussion\n",
    "\n",
    "Before we  begin building our models for comparison, we plotted the histogram distribution of each feature in the dataset to have an insight on the features, using  0 and 1 representing the non-diabetic class(blue) and the diabetic class(orange) respectively. It is seen that for all the features, there is a significant overlapping in between the classes as most of the features are binary features. However, their max and mean values for each feature seems to be different, thus, we decided to include all the features in our model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../results/figures/feature_histogram_by_class.png\n",
    "---\n",
    "width: 800px\n",
    "name: feature_histogram_by_class\n",
    "---\n",
    "Histogram distribution for each feature in the training data for both non-diabetic (0 & blue) and diabetic (1 & orange) class.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a random search, we performed hyperparameter optimization on a knn model and a decision tree model. For the knn model, we found that the optimal value for n_neighbors was {glue:text}`knn_bestparam`. For the decision tree model, we found the optimal value for max_depth to be {glue:text}`tree_bestparam`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then compared the two optimized models to a dummy classifier and a logistic regression model. The optimized decision tree model out-performed all others, with a cross validation score of {glue:text}`dt_test_score`. As seen in the table below  ({numref}`Figure {number} <model_score_table>`), all of the scores were quite high for all models, even the dummy model. This is likely due to the imbalance in the target features, which should be addressed if this model were to be improved and used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:figure} model_score_table\n",
    ":figwidth: 700px\n",
    ":name: \"model_score_table\"\n",
    "\n",
    "Cross validation results for all optimized models, as a result of a random search hyperparamater optimization, compared to a dummy classifier.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the logistic regression model did not have the best performance compared to the other models, with a cross-validation score of {glue:text}`lr_test_score` its coefficients were still useful in investigating which features were weighted as more important in indicating whether a person has diabetes/prediabetes. The results, shown in the table below ({numref}`Figure {number} <coef_table>`), indicate that general health (GenHlth), is the largest predictor of diabetes/prediabetes, followed by body mass index (BMI), high blood pressure (HighBP), and age, respectively. All of these factors, unsurprisingly had a positive correlation with the presence of diabetes/prediabetes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:figure} coef_table\n",
    ":figwidth: 700px\n",
    ":name: \"coef_table\"\n",
    "\n",
    "Logistic regression coefficients by feature.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To enhance the future iterations of this model for potential use in medical pre-diagnosis, we propose the following recommendations:\n",
    "\n",
    "1.\tBegin by closely examining instances of {glue:text}`false_negative` misclassifications as well as {glue:text}`false_positive`, comparing them to correctly classified observations from both classes. The objective is to identify features driving misclassifications and explore potential feature engineering to improve the model's accuracy on these problematic observations.\n",
    "\n",
    "2.\tInvestigate alternative classifiers to determine if enhanced predictions can be attained. A potential option is to employ a random forest classifier, which inherently considers feature interactions, in contrast to the k-NN model.\n",
    "\n",
    "3.\tAcknowledge the significant class imbalance between diabetic and non-diabetic classes and address it in the preprocessor for subsequent analyses.\n",
    "\n",
    "4.\tEnhance the model's usability in diagnosis by providing and reporting probability estimates for predictions. This approach ensures that even if misclassifications persist, clinicians with domain knowledge can gauge the model's confidence in its predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{bibliography}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
